---
layout: pr
date: 2023-01-11
title: "Track active requests and wait for last to finish"
pr: 26742
authors: [fjahr]
components: ["rpc/rest/zmq"]
host: stickies-v
status: past
commit: 6d3a848fc76f76af2b2b262011f37be952325b44
---

## Notes

- First, we'll have a more general look at Bitcoin Core's HTTP server to build an essential understanding of the area we're working on. Then we'll dive deeper into the specifics of this PR.

### HTTP server

- Since [#5677](https://github.com/bitcoin/bitcoin/pull/5677), Bitcoin Core's [HTTP server](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httpserver.cpp#L138-L139) is based on [libevent2](https://libevent.org/). Libevent is a general purpose event notification library, but is used in Bitcoin Core specifically for HTTP requests (which it supports natively).

- Much (not all) of the libevent interface is hidden behind wrappers. For example, [`HTTPRequest`](https://github.com/bitcoin/bitcoin/blob/296e88225096125b08665b97715c5b8ebb1d28ec/src/httpserver.h#L56) wraps `evhttp_request` and [`HTTPEvent`](https://github.com/bitcoin/bitcoin/blob/296e88225096125b08665b97715c5b8ebb1d28ec/src/httpserver.h#L154) wraps [`event_base`](https://libevent.org/doc/structevent__base.html)

- The relevant workflow for how (for example) an RPC request is handled is roughly as follows:

  1. the HTTP server receives an RPC command from a caller, creates an `evhttp_request` object and passes its pointer to `http_request_cb()` (this step is completely handled by libevent)

  2. an `HTTPWorkItem` is [created](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httpserver.cpp#L261), containing the `evhttp_request` (wrapped in `HTTPRequest hreq`) as well as the path and reference to the handler function (which contains the business logic to be executed to deal with the request)

  3. the `HTTPWorkItem` [is put on the global](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httpserver.cpp#L263) `WorkQueue g_work_queue`, which [is processed](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httpserver.cpp#L336-L341) by multiple worker threads asynchronously

  4. when the handler function of a `HTTPWorkItem` completes successfully, it calls [`HTTPRequest::WriteReply()`](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httprpc.cpp#L230), which triggers the libevent function [`evhttp_send_reply()`](https://libevent.org/doc/http_8h.html#a0a77d07263e20733a7562dcd576ad721), which in turn returns a response to the caller and destroys the `evhttp_request` object.

- Endpoints are registered to the HTTP server by calling `RegisterHTTPHandler()`, such as e.g. in [`StartHTTPRPC()`](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httprpc.cpp#L301-L303)

- The HTTP server is initiated and started from `AppInitServers()`, and stopped from `Shutdown()`

- `StartHTTPServer()` [adds](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httpserver.cpp#L430) a thread for each worker to `g_thread_http_workers`. These threads will keep running until [`WorkQueue::Interrupt()`](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httpserver.cpp#L118) sets `running` to `false` and [the queue is empty](https://github.com/bitcoin/bitcoin/blob/adc41cf3b22f8f168e88ce3ad5f27c1130f12beb/src/httpserver.cpp#L106).

### This PR

- This PR changes `StopHTTPServer()` to destroy the `eventHTTP` HTTP server (by calling `evhttp_free(eventHTTP`)) as soon as all workers have finished executing their tasks, making the shutdown process significantly faster.

- Libevent [requires](https://github.com/libevent/libevent/blob/1cea01d6d5c84337dac663e5464059ccd2d6a8dd/include/event2/http.h#L208-L217) that no requests are being served when `evhttp_free()` is called, so we keep track of all the requests created by libevent that have not yet been completed in `g_requests`.

- The change is unlikely to be significant to users, since node shutdowns are typically not very frequent. It does however significantly speed up (verify this yourself!) the `feature_abortnode.py` functional test, consequently speeding up developer workflows *worldwide*.

## Questions
1. Did you review the PR? [Concept ACK, approach ACK, tested ACK, or NACK](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md#peer-review)?

1. Which of Bitcoin Core's interface(s) (RPC, REST, ZMQ) make use of the HTTP server? For each interface, how many handlers are registered to `pathHandlers`?

1. We [already wait](https://github.com/bitcoin-core-review-club/bitcoin/commit/cc663803d363b974baee17337608843d038ccda2#diff-63c8cb9c9dd61d50d59afd5c39914e1c259f8743030b637a7896a0746c851ef1R467-R473) for all threads in `g_thread_http_workers` to be joined before destroying `eventHTTP`, which only happens when the queue is empty (see notes) - so we would expect all requests to be handled by then. Why do we separately need to track `evhttp_request` objects, too?

1. What's the purpose of `g_requests`? Can you think of any alternative approaches that would achieve the same goal?

1. Which (smallest possible) part of the code change in this PR is responsible for the drastic performance speedup in `feature_abortnode.py`, and why is that making it faster?

1. What is a `GlobalMutex`, and why is it used here?

1. What does the `EV_TIMEOUT` passed to `event_base_once()` mean, and why is it used here?

1. (Bonus): why do we have both a `StartRPC()` as well as a `StartHTTPRPC()` function?

## Meeting Log

{% irc %}
17:00 <stickies-v> #startmeeting
17:00 <d33r_gee> hello
17:00 <effexzi> Hi every1
17:00 <emzy> hi
17:00 <svav> Hi there
17:00 <codo> hi
17:01 <stickies-v> welcome everyone - thank you for joining us again in the new year! Today we're looking at #26742, authored by fjahr, building on previous work done by promag. The notes and questions are available on https://bitcoincore.reviews/26742
17:01 <stickies-v> is anyone joining us for the first time today? even if you're just lurking, feel free to say hi!
17:01 <brunoerg> hi!
17:02 <Yaz> hi
17:02 <codo> first timer, probably just lurking
17:02 <Yaz> first time here, tried to understand as much as possible from the PR :)
17:02 <LarryRuane> hi
17:03 <rozehnal_paul> hi
17:03 <stickies-v> awesome, great to have you here codo, and Yaz ! lurking is great, but feel free to ask or contribute as much as you want
17:03 <glozow> hi
17:04 <stickies-v> who got the chance to review the PR or read the notes? (y/n)
17:04 <rozehnal_paul> y
17:04 <Yaz> y
17:04 <emzy> n just read notes and pr.
17:04 <codo> y
17:04 <LarryRuane> n (only a little)
17:04 <svav> Read the notes
17:05 <stickies-v> it's a pretty small PR in terms of LoC changed, but it pulled me down much deeper a rabbit hole than I expected
17:05 <LarryRuane> The condition variable stuff is really cool, but takes some studying to understand
17:06 <stickies-v> for those of you who were able to review, would you give it a Concept ACK, Approach ACK, Tested ACK, or NACK?
17:06 <stickies-v> LarryRuane: same here! we use it in other places in the code too, but this is the first time I properly looked at it
17:06 <LarryRuane> concept ACK for sure
17:07 <rozehnal_paul> concept ACK - will expedite testing in the future
17:07 <LarryRuane> the concept goes all the way back to the UNIX kernel sleep()/wakeup() synchronization mechanism (which i've always loved)
17:07 <LarryRuane> (tells you how old i am!)
17:08 <Yaz> I dont know if this should be asked here/know
17:08 <Yaz> Why was there a significant performance boost in testing ~31 seconds improvement
17:08 <stickies-v> Yaz: we'll cover that in one of the questions - hang tight!
17:09 <stickies-v> quick note before diving into the questions: the PR has been updated slightly since these notes were released, so the current commit hashes are different. I'll keep linking to the "old" (6d3a848 and earlier) commits here.
17:09 <stickies-v> to start off - how would you briefly summarize what this PR is doing?
17:10 <svav> Makes node shutdowns faster so improves developer workflow and productivity.
17:12 <stickies-v> svav: yes, that's the purpose of the PR and the main effect of the code
17:12 <Yaz> I did not understand the purpose of the PR, unfortunatelyÂ :(
17:13 <rozehnal_paul> Yaz the change is subtle, and not really user-facing. like svav said, nodes can shutdown faster now, a small but noticeable benefit
17:13 <stickies-v> most of the code of the PR actually does not (directly) contribute to the performance improvement, but deals with shutting down the HTTP server safely, i.e. ensure we don't kill it before all inbound requests are dealt with in one way or another
17:14 <stickies-v> Yaz: an easy way to observe the effect of the PR is by running `./test/functional/feature_abortnode.py` and on this branch. You should notice a drastic speedup on this branch
17:15 <stickies-v> alright, moving on to the prep questions
17:15 <stickies-v> 1. Which of Bitcoin Core's interface(s) (RPC, REST, ZMQ) make use of the HTTP server? For each interface, how many handlers are registered to `pathHandlers`?
17:15 <stickies-v> (as always - feel free to continue discussing previous questions while we move on to the next one)
17:15 <svav> Well RPC definitely does ...
17:15 <Yaz> Thank you stickies-v rozehnal_paul
17:16 <LarryRuane> stickies-v: "You should notice a drastic speedup on this branch" -- you're right, with this branch takes my system about 1.5s, without takes 31s
17:17 <rozehnal_paul> 1. definitely rpc interface is involved
17:17 <rozehnal_paul> and rest
17:17 <LarryRuane> "Which of Bitcoin Core's interface(s) ..." -- I believe all of them do (but I don't know the answer to the second question)
17:18 <stickies-v> rozehnal_paul: yes, both RPC and REST rely on the HTTP server! So, ZMQ is the only one that doesn't
17:19 <Yaz> I am definitely not on the same level as you are.
17:19 <Yaz> Is this related to when a user sends a request to his/her node?
17:19 <Yaz> Or is it related to a user relaying blocks/transactions?
17:20 <svav> Would I be right in saying ZMQ (ZeroMQ) is lower level and relies on TCP/IP?
17:20 <stickies-v> LarryRuane: as a hint, the handlers are stored in `pathHandlers` (https://github.com/bitcoin/bitcoin/blob/329d7e379d09fa5db9c057baa0e100d2b174427d/src/httpserver.cpp#L146)
17:21 <stickies-v> Yaz: the RPC, REST and ZMQ interfaces are meant to directly interact with your node (e.g. request or alter information about your wallet, transactions, blocks, ...) in a user-facing way. This is separate from the networking that your node does with other peers, to relay blocks, transactions and addresses etc, which it needs to do in order to be operational
17:22 <LarryRuane> stickies-v: seems to be only http and REST
17:22 <Yaz> stickies-vÂ (y)
17:22 <stickies-v> svav: I'm actually not familiar at all with ZMQ. I just checked whether it was using the HTTP server ð which, it doesn't
17:22 <LarryRuane> (i.e. not ZMQ as far as i can tell)
17:23 <stickies-v> we have 2 handlers for RPC: https://github.com/bitcoin/bitcoin/blob/9887fc789886b356efc6818783cabaab2b14481f/src/httprpc.cpp#L301-L303
17:23 <stickies-v> and another 12 handlers for REST: https://github.com/bitcoin/bitcoin/blob/9887fc789886b356efc6818783cabaab2b14481f/src/rest.cpp#L973-L997
17:23 <svav> Is it four handlers per interface?
17:24 <LarryRuane> http registers 2 handlers, "/" and "/wallet" ... oh REST registers a bunch of them!
17:24 <LarryRuane> (haha sorry i was late with that)
17:25 <stickies-v> LarryRuane: yes, which may be surprising given that the RPC interface is much more extensive. For RPC, we've just standardized the way we organize RPC methods quite well, so we can abstract all that away with just 2 handlers. For REST, however, everything is kinda ad-hoc, and every endpoint is its own handler
17:26 <LarryRuane> so REST could be improved?
17:26 <stickies-v> I just realized my previous answer was not quite nuanced enough
17:27 <stickies-v> I think a big reason (speculating) why we have the handlers the way we do, is because REST calls follow the HTTP URI scheme, where the endpoint is encoded in the URI (e.g. http://somewebsite.com/my/endpoint). For RPC, we don't include the method in the URI but in the payload, I think?
17:28 <rozehnal_paul> +1 Larrys question
17:28 <LarryRuane> if anyone would like to fire up REST, add `-rest` to your config, restart, then for example `curl -s localhost:8332/rest/chaininfo.json|json_pp`
17:28 <stickies-v> but the fact remains that for the RPC we have a lot more standardization (`RPCHelpMan`, `RPCArg`, etc...) than for REST
17:29 <LarryRuane> (or, you don't really need to `json_pp`, just a pretty-printer)
17:29 <stickies-v> 2. We already wait for all threads in `g_thread_http_workers` to be joined before destroying `eventHTTP`, which only happens when the queue is empty (see notes) - so we would expect all requests to be handled by then. Why do we separately need to track `evhttp_request` objects, too?
17:31 <svav> Is a pathhandler a Handler that dispatches to a given handler based on a prefix match of the path? Thanks
17:32 <stickies-v> svav: yes, exactly, see https://github.com/bitcoin/bitcoin/blob/329d7e379d09fa5db9c057baa0e100d2b174427d/src/httpserver.cpp#L241-L272
17:32 <stickies-v> basically the handler tells us which business logic we need to execute in order to satisfy a certain request
17:33 <LarryRuane> "Why do we separately need to track `evhttp_request` objects, too?" -- I couldn't figure this out
17:33 <stickies-v> LarryRuane: can you think of any synchronization issues?
17:34 <LarryRuane> oh, when the queue is empty (and we're not allowing any new requests to be enqueued), there could still be requests in progress?
17:34 <rozehnal_paul> for (; i != iend; ++i)
17:34 <rozehnal_paul> the first statement that is left empty is shorthand for i starts at 0, correct?
17:34 <LarryRuane> rozehnal_paul: no
17:35 <stickies-v> rozehnal_paul: we've already initialized `i` two lines higher up
17:35 <LarryRuane> also, `i` is not an integer, it's an iterator (often called `it` but here only `i`)
17:36 <rozehnal_paul> ah, thx
17:36 <stickies-v> LarryRuane: yes, exactly. I'd say in probably >99% of the time they should be synchronized, but if a new request comes in right before stopping the HTTP server, it's possible that the queue is empty and it looks like we can terminate but we actually still need to process that last-minute request
17:38 <stickies-v> so, there's a bit of overlap with the next question but it's still worth looking at separately:
17:38 <stickies-v> 3. What's the purpose of `g_requests`? Can you think of any alternative approaches that would achieve the same goal?
17:38 <LarryRuane> some requests can take a long time, right? like `gettxout`?
17:39 <stickies-v> LarryRuane: yes, but that's not really the issue here. Once a request is added onto `g_work_queue`, it will prevent the worker threads from terminating. So we wouldn't terminate the HTTP server prematurely
17:40 <svav> Does the g of g_requests stand for global?
17:40 <LarryRuane> i know the convention is that the `g_` means it's a global variable (so they're easier to identify when we want to assassinate them later)
17:40 <stickies-v> it's just that libevent requires there to be no unhandled requests when we call `evhttp_free(eventHTTP)`, which we need to ensure ourselves
17:40 <stickies-v> svav: yes!
17:43 <stickies-v> so `g_requests` simply keeps track of all the `evhttp_request` objects created by libevent, so we can easily keep track of whether or not they're all destroyed before we destroy `eventHTTP`
17:44 <stickies-v> I see two alternative solutions: we could use a lock for almost the entire duration of `http_request_cb` to ensure that no requests are being processed to be put in the `g_work_queue`, but that would be quite expensive
17:45 <stickies-v> a more elegant approach is that instead of tracking all the `evhttp_request` objects (or well, pointers to them), we could just keep a simple counter on how many requests we haven't yet handled, as discussed here: https://github.com/bitcoin/bitcoin/pull/26742#discussion_r1063664153
17:45 <rozehnal_paul> i was curious what the cb stood for in 'http_request_bc'
17:46 <stickies-v> (however, follow up PRs would benefit from tracking the actual requests instead of a counter)
17:46 <stickies-v> rozehnal_paul: it stands for callback
17:46 <stickies-v> https://en.wikipedia.org/wiki/Callback_(computer_programming)
17:46 <stickies-v> 4. Which (smallest possible) part of the code change in this PR is responsible for the drastic performance speedup in `feature_abortnode.py`, and why is that making it faster?
17:47 <stickies-v> (Yaz - now we're dealing with your question at the beginning of the review club!)
17:47 <rozehnal_paul> stickies-v is it the use of the atomic counter?
17:47 <stickies-v> rozehnal_paul: is that a response to the question of the performance speedup?
17:48 <Yaz> Thank you for the heads upÂ (y) (y)
17:49 <rozehnal_paul> yes
17:49 <stickies-v> then, no. the PR doesn't use an atomic counter, that's just something I suggested but is not implemented (because we need to track the actual requests in a follow up PR, so fjahr would rather not change that again)
17:51 <rozehnal_paul> now we dont wait for a timeout
17:51 <rozehnal_paul> https://github.com/bitcoin/bitcoin/pull/26742#issuecomment-1375580720
17:52 <glozow> https://github.com/bitcoin/bitcoin/pull/26742/files#diff-63c8cb9c9dd61d50d59afd5c39914e1c259f8743030b637a7896a0746c851ef1R493 ?
17:52 <stickies-v> rozehnal_paul: yes, that's what it boils down to. but why don't we wait for a timeout anymore?
17:52 <stickies-v> glozow: are you referring to the addition of `event_base_once`?
17:53 <svav> It's the change to the way StopHTTPServer() works
17:53 <svav> Now, as soon as all worked have finished executing their tasks, evhttp_free(eventHTTP) is called, destroying the eventHTTP HTTP server
17:53 <svav> all *workers*
17:54 <LarryRuane> svav: +1
17:54 <stickies-v> svav: almost, but not 100%
17:54 <svav> ok enlighten me
17:55 <stickies-v> the majority of the code in this PR is to make it go from "as soon as all the workers have finished executing their tasks" to "as soon as all the `evhttp_request` objects created by libevent have been destroyed
17:55 <stickies-v> in case of the former, this PR could have been limited to just moving `if (g_thread_http.joinable()) g_thread_http.join();` a few lines down, after `evhttp_free(eventHTTP)` has been called (https://github.com/bitcoin-core-review-club/bitcoin/commit/6bd3394c80d2f11ef30c671b03c38985f72df44c#diff-63c8cb9c9dd61d50d59afd5c39914e1c259f8743030b637a7896a0746c851ef1L491)
17:56 <stickies-v> (you can easily verify this yourself by making just that small change on master, and running `feature_abortnode.py`)
17:57 <stickies-v> BUT we may encounter the edge case that we call `evhttp_free(eventHTTP)` before all `evhttp_request` objects have been destroyed, which libevent does not allow (I'm not sure if it leads to a crash, UB, or anything else)
17:57 <LarryRuane> so at line 500 (in the new code), we do call `join()`, is that path not normally taken (only if `eventBase` is not null)?
17:58 <svav> Re Q6 I would just like to mention that a mutex is analogous to a rubber chicken being used in a meeting which people have to be holding to allow them to talkÂ :')
17:58 <stickies-v> `eventBase` is never expected to be null, afaict
17:58 <stickies-v> svav:  hahahahahaha please create a PR to update the documentation
17:59 <stickies-v> does anyone know *why* just switching those few lines leads to such a performance improvement?
18:00 <svav> Is it something to do with the number of processes that need to be monitored?
18:00 <stickies-v> svav: I don't think so
18:01 <codo> My understanding was it closes network connections so the do not linger idle.
18:01 <LarryRuane> oh wow, so `GlobalMutex` behaves exactly like `Mutex` but this is sort of a documentation thing?
18:01 <stickies-v> `g_thread_http` is the thread in which we run the HTTP server, and even though all the `evhttp_request`s may be handled, connections to the HTTP server can still be open, albeit idle. Calling `g_thread_http.join()` will not return until also all idle connections are closed
18:02 <stickies-v> calling `evhttp_free(eventHTTP)` however, will forcefully destroy the HTTP server, cleaning up all idle connections too
18:02 <stickies-v> so `g_thread_http.join()` now returns immediately
18:02 <stickies-v> hope that makes sense - we're at time now so I'll close it up here but feel free to keep discussing here, of course
18:02 <stickies-v> thank you all for joining the conversation!
18:03 <stickies-v> #endmeeting
{% endirc %}
